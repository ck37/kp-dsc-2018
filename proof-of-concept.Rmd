---
title: "import data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
 

# Contains custom SuperLearner wrappers and screeners.
source("R/sl-library.R")

library(ggplot2)
library(SuperLearner)
library(data.table)
library(xgboost)
library(glmnet)
library(ranger)
library(doParallel)
# Install this version, the CRAN version is very old sadly --
# devtools::install_github("ck37/ck37r")
library(ck37r)
```

```{r import_data}

data = data.table::fread("data-raw/train.csv")
dim(data)

names(data) = tolower(names(data))

table(sapply(data, class))
sapply(data, class)

# Define our outcome variable.
var_outcome = "label"

tibble::glimpse(data)

# No missing data - NAs at least.
colMeans(is.na(data))

# Review our outcome distribution - not imbalanced.
table(data[[var_outcome]], useNA = "ifany")
```

```{r data_prep}
remove_cols = c(var_outcome,
                # Simply notes that this is all training data.
                "kaggleset",
                # TODO: figure out what these columns mean.
                "eventid", "kaggleweight", "weight")
x = as.data.frame(data)[, !names(data) %in% remove_cols]
y = as.numeric(data$label == "s")
```

# Correlation analysis

```{r eda_corr}
corr = ck37r::vim_corr(names(x), cbind(y, x), "y", bootse = FALSE)

# Look at the top 20 covariates most correlated with the outcome.
# All are incredibly significant.
head(corr, n = 20)
```

# OLS analysis

```{r eda_reg}
reg = lm(y ~ ., data = x)

# Adj. R-sqr of 0.2464
summary(reg)
```

# Most basic model possible

```{r model_sl}

# This will select only the top 5 covariates based on correlation with the outcome.
screen.corRank5 = function(...) screen.corRank2(..., rank = 5)

# Setup parallel backend for glmnet_fast.
doParallel::registerDoParallel(cores = RhpcBLASctl::get_num_cores())

# Add screeners so that it's not as slow to estimate.
# TODO: test wider numbers of covariates, e.g. 15 or all.
# TODO: grid search on xgboost hyperparameters.
sl_lib = list(c("SL.xgboost_fast", "screen.corRank5"),
              c("SL.ranger_fast", "screen.corRank5"),
              c("SL.glmnet_fast", "screen.corRank5"),
                "SL.mean")

set.seed(3137033, "L'Ecuyer-CMRG")
sl = SuperLearner::SuperLearner(Y = y, X = x,
                  family = binomial(),
                  verbose = TRUE,
                  SL.library = sl_lib,
                  # TODO: consider method = nnlogLik
                  cvControl = SuperLearner.CV.control(V = 3L))
                  # Re-run with 20 folds when we want to finalize our model.
                  # cvControl = SuperLearner.CV.control(V = 20L))
sl

# Review auc of the learners.
# xgboost and ranger are both around 0.88, glmnet at 0.77
ck37r::auc_table(sl, y = y)
# TODO: export table.

# Plot ROC curve.
ck37r::plot_roc(sl, y = y)
ggsave("visuals/roc-proof-of-concept.png")

# Save our results
save(sl,
     file = "data/model-proof-of-concept-sl.RData")
```

# Predict on test

```{r test_prediction}
test = data.table::fread("data-raw/test.csv", data.table = FALSE)
dim(test)

(names(test) = tolower(names(test)))

# Restrict to columns that we want.
test_df = test[, !names(test) %in% c("weight", "kaggleset", "kaggleweight", "eventid")]

# Apply SuperLearner to generate predictions.
predictions = predict(sl, test_df, onlySL = TRUE,
                      num.threads = RhpcBLASctl::get_num_cores())$pred

summary(predictions)

qplot(predictions) + theme_minimal()
ggsave("visuals/hist-proof-of-concept.png")

# Currently guessing that $eventid is the primary id for each observation.
export = data.frame(EventId = test$eventid, Label = predictions)

# Convert probability prediction to a class prediction.
export$Label = ifelse(export$Label > 0.5, "s", "b")

table(export$Label)
prop.table(table(export$Label))

# Generate a csv file to upload to competition submission page.
rio::export(export, file = "exports/proof-of-concept.csv")

```
