---
title: "Model: SL basic"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

# Load an initial pair of startup functions.
source("R/_startup.R")
# Load necessary libraries; set auto_install = TRUE to try to install any needed packages.
startup(auto_install = FALSE, verbose = FALSE,
        # We are assuming this model is being run on a server with 128GB+ RAM.
        # TODO: this is not enough memory - need to increase.
        java_mem = "120g")
# Load all .R files in the R/ subdirectory.
ck37r::load_all_code("R", verbose = TRUE)

# File created in clean.Rmd
load("data/clean.RData")

# Define a model name specifically for this Rmd file.
task$model_name = "sl-slower"
```

## Define estimators

```{r define_estimators}

# This will select only the top 15 covariates based on correlation with the outcome.
screen.corRank15 = function(...) screen.corRank2(..., rank = 15)
screen.corRank25 = function(...) screen.corRank2(..., rank = 25)

# Create 9 combinations of settings for xgboost.
xgb_grid =
  create.Learner("SL.xgboost_fast", name_prefix = "xgb",
                 detailed_names = TRUE,
                 tune = list(
                   # TODO: conduct more extensive hyperparameter tuning.
                   shrinkage = c(0.001, 0.01, 0.1),
                   max_depth = c(1, 4, 8)
                 ))
xgb_grid$names

# Setup parallel backend for glmnet_fast.
doParallel::registerDoParallel(cores = RhpcBLASctl::get_num_cores())
foreach::getDoParWorkers()

bartMachine::set_bart_machine_num_cores(RhpcBLASctl::get_num_cores())
bartMachine::bart_machine_num_cores()

# Confirm that we have 120GB+ allocated to rJAva.
invisible(ck37r::get_java_memory(verbose = TRUE))
sl_lib =
  c(lapply(xgb_grid$names, function(name) c(name, "All", "screen.corRank25")),
    list(c("SL.xgboost_fast", "All", "screen.corRank25"),
         c("SL.bartMachine2", "All", "screen.corRank25"),
         # Broken, need to fix:
         # Error in check.booster.params(params, ...) : 
  # Same parameters in 'params' and in the call are not allowed. Please check your 'params' list.
 #        c("SL.xgboost_cv", "All", "screen.corRank25"),
         c("SL.ranger_fast", "All", "screen.corRank25"),
         c("SL.glmnet_fast", "All", "screen.corRank25"),
         # TODO: add ck37r::SL.h2o_auto
         "SL.mean"))

```

## Run estimation

```{r superlearner}

# Set a multicore-compatible seed for reproducibility.
set.seed(3137033, "L'Ecuyer-CMRG")
sl =
  SuperLearner(Y = task$outcome,
               X = task$data[, task$covariates],
               family = binomial(),
               verbose = TRUE,
               SL.library = sl_lib,
               # TODO: consider method = nnlogLik
               cvControl = SuperLearner.CV.control(V = 5L))
               # Re-run with 20 folds when we want to finalize our model.
               # cvControl = SuperLearner.CV.control(V = 20L))

sl

# 743 mins on Benten
cat("Execution time:", round(sl$times$everything["elapsed"] / 60, 1), "minutes.\n")

# Save our results and our task for posterity.
save(sl, task,
     file = paste0("data/model-", task$model_name, ".RData"))
```

## Review model

```{r review_model}
# Review auc of the learners.
ck37r::auc_table(sl, y = task$outcome)
# TODO: export table.

# Plot ROC curve.
# TODO: fix this, currently broken.
ck37r::plot_roc(sl, y = task$outcome)
ggsave(paste0("visuals/roc-", task$model_name, ".png"))

# Plot predictions.
qplot(sl$SL.predict) + theme_minimal()
ggsave(paste0("visuals/training-predictions-", task$model_name, ".png"))

labels = as.numeric(sl$SL.predict > 0.5, 1, 0)
table(labels, task$outcome, useNA = "ifany")
# 88% internal estimate, but 83% based on leaderboard submission.
(accuracy = mean(labels == task$outcome))

# TODO: identify optimal threshold.

# TODO: calculate the class label based AUC using the cross-validation folds rather than resubstitution.

# TODO: review OOB curve for ranger model.

```

## Predict on test

TODO: convert more of this code to functions so that it isn't duplicated across model files.

```{r test_prediction}

# Apply SuperLearner to generate predictions.
# Takes 1 - 4 minutes.
system.time({
  predictions =
    predict(sl, task$data_test,
            # Only estimate the models that are used in the SL ensemble.
            onlySL = TRUE,
            # Allow multithreaded prediction to speed this up.
            num.threads = RhpcBLASctl::get_num_cores())
})

predictions = predictions$pred[, 1]

# Review prediction distribution.
summary(predictions)
qplot(predictions, bins = 100L) + theme_minimal()
ggsave(paste0("visuals/test-hist-", task$model_name, ".png"))

cutpoints = unique(sl$SL.predict)

cutpoints = seq(0, 1, by = 0.001)
results = data.frame(matrix(NA, nrow = length(cutpoints), ncol = 6))
colnames(results) = c("cutpoint", "tpr", "fpr", "diff", "accuracy", "auc")

# Calculate true positive rate and false positive rate for each possible cutpoint.
for (cutpoint_i in seq_along(cutpoints)) {
  point = cutpoints[cutpoint_i]
  labels = as.integer(sl$SL.predict > point)
  accuracy = mean(labels == task$outcome)
  tpr = mean(labels[task$outcome == 1])
  fpr = mean(task$outcome == 0 & labels == 1)
  # Quick way to estimate AUC, there may be a better formula.
  auc = mean(sample(labels[task$outcome == 1], 5000, replace = TRUE) >
             sample(labels[task$outcome == 0], 5000, replace = TRUE))
  results[cutpoint_i, ] = list(point, tpr, fpr, tpr - fpr, accuracy, auc)
}

results
qplot(results$fpr, results$tpr)

# 0.277
cutpoints[which.max(results$diff)]
# 0.31
cutpoints[which.max(results$auc)]

summary(results)
mean(task$outcome)

# TODO: remove unnecessary legend, label vertical lines.
qplot(results$cutpoint, results$auc, alpha = 0.5) +
  theme_minimal() +
  scale_x_continuous(limits = c(0.1, 0.6)) +
  scale_y_continuous(limits = c(0.5, 0.85)) + 
  geom_smooth() + 
  geom_vline(xintercept = mean(task$outcome), color = "red", alpha = 0.5) +
  #geom_vline(xintercept = 0.35, color = "red", alpha = 0.5) +
  #geom_vline(xintercept = 0.34, color = "purple", alpha = 0.5) +
  #geom_vline(xintercept = 0.32, color = "darkgreen", alpha = 0.5) +
  #geom_vline(xintercept = 0.27, color = "orange") +
  geom_vline(xintercept = 0.5, color = "gray50") +
  labs(x = "Cutpoint", y = "Estimated AUC")

ggsave(paste0("visuals/cutpoint-analysis-", task$model_name, ".png"))

# Create a dataframe that contains just what we need to submit an entry.
# $eventid is the primary id for each observation.
export = data.frame(EventId = task$id_test, Label = predictions)

# Convert probability prediction to a class prediction.
# TODO: run optimal threshold analysis to decide best probability threshold.
#threshold = 0.35
(threshold = round(mean(task$outcome), 4))
export$Label = ifelse(export$Label > threshold, "s", "b")

# Review predicted class labels.
table(export$Label)
prop.table(table(export$Label))

# Generate a csv file to upload to competition submission page.
# TODO: add date+time to filename?

rio::export(export,
            file = paste0("exports/submission-", task$model_name, "-",
                          threshold, "-", 
                          format(Sys.time(), "%m-%d"), ".csv"))

```

## Multiple thresholds 

Run this manually to generate exports across multiple thresholds to optimize the classification cutpoint.

```{r multiple_thresholds, eval=F}
# Create a dataframe that contains just what we need to submit an entry.
# $eventid is the primary id for each observation.

# 0.32 and 0.33 are slightly worse on public leaderboard than 0.3427
# These also don't improve on 0.3427 :/
thresholds = c(0.341, 0.342, 0.344)

for (threshold in thresholds) {
  cat("Processing threshold", threshold, "\n")
  
  export = data.frame(EventId = task$id_test, Label = predictions)

  # Convert probability prediction to a class prediction.
  export$Label = ifelse(export$Label > threshold, "s", "b")

  # Review predicted class labels.
  print(table(export$Label))
  print(prop.table(table(export$Label)))

  # Generate a csv file to upload to competition submission page.

  rio::export(export,
              file = paste0("exports/submission-", task$model_name, "-",
                            threshold, "-", 
                            format(Sys.time(), "%m-%d"), ".csv"))
}
  
```
